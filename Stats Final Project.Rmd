---
title: "Stats Final Project"
author: "Fatima Fairfax"
date: "4/6/2022"
output: html_document
---

```{r load packages}
#loading all the packages I'll need

library(MatchIt) #for matching
library(WeightIt) #for weighting
library(cobalt) #for assessing the degree of balance
library(tidyverse)
library(broom)
library(haven)

theme_set(theme_minimal())
```


# Research Question 1:  Does having health related apps correlate with improve self-rated health?

```{r}
app_health <- app_health |> relocate(Apps) |> select(-TabletHealthWellnessApps)
glimpse(app_health)
```


```{r data set up - weights}
# add weights

app_health <- app_health |> 
  mutate(weight = 1)

# estimate treatment effects - ATT or ATE?

app_est_1 <- lm(health ~ Apps,
           data = app_health,
           weights = weight)

tidy(app_est_1, conf.int = TRUE)
```

    This gives a coefficient of 0.21 on the "treatment," that is staitistically significant at the 95% level. This means that having an app makes you a little more likely to have good health (1 = excellent and 5 = poor)
    

```{r balance table}
app_health |> 
  group_by(Apps) |> 
  summarize(across(IncomeRanges:female,~mean(.x)))
```

The balance here is actually pretty good! **check why that is**

## Matching 

*come back to see if we want the ATT or the ATE*

Use all the variables except for the treatment (Apps) and the GeneralHealth variables. 

```{r ATT for Question 1 with matching}
match_1 <- matchit(Apps ~ IncomeRanges + Age + HealthInsurance + Education + white + black + hisp + asian + other_race + female,
                  data = app_health,
                  method = "nearest",
                  distance = "mahalanobis",
                  estimand = "ATT",
                  ratio = 3, #to make it a 3-nearest-matching
                  replace = TRUE)

summary(match_1,
        un = FALSE,
        improvement = FALSE)
```



```{r Post-Matching average treatment on the treated effect of Apps on GeneralHealth}

#### get matched data for calculating weighted difference
md1 <- match.data(match_1)

#### cobalt balance checks
bal.plot(match_1,
         which = "both",
         mirror = TRUE)

love.plot(match_1,
          abs = TRUE,
          binary = "std",
          thresholds = .1)


#### compute weighted difference (ATT)
matchdiff1 <- lm(health ~ Apps,
                 data = md1,
                 weights = weights)

tidy(matchdiff1, conf.int = TRUE)


```

**With mahalabonis 3-nearest matching, having health apps on your tablet is correlated with a 0.063 unit increase in self-rated health. This result is statistically significant at the 95% level.** 


```{r post matching balance}
md1 |> 
  group_by(Apps) |> 
  summarize(across(IncomeRanges:female,~weighted.mean(.x,weights)))
```

Better matching - though it was pretty close. 

### Propensity Matching

```{r Estimate propensity score}
#estimate the propensity score
p <- glm(Apps ~ IncomeRanges + Age + HealthInsurance + Education + white + black + hisp + asian + other_race + female,
         data = app_health, family = binomial(link = 'logit'))

#get predicted values
app_health <- app_health |> 
  mutate(propensity = predict(p,type = 'response'))

glimpse(app_health)
```

Check if propensity is between 0 and 1

```{r}
range(app_health$propensity)
```

Yes, all good. 


```{r create ipw and estimate the ATT}
#create IPW weights
app_health <- app_health |> 
  mutate(ipw = case_when(
    Apps == 1 ~ 1/propensity,
    Apps == 0 ~ 1/(1-propensity)
  ))

#and use to weight regressions

lm(health ~ Apps,
   data = app_health,
   weights = ipw)
```

**With propensity score matching and weights, having a health app is associated with a 0.05 point increase in self-rated health**


```{r steve weighting methods}
#### do the weighting
weight_ps <- weightit(Apps ~ IncomeRanges + Age + HealthInsurance + Education + white + black + hisp + asian + other_race + female,
                  data = app_health,
                  method = "ps",
                  estimand = "ATT")

#### summary
summary(weight_ps)

#### cobalt balance checks
bal.plot(weight_ps,
         which = "both",
         mirror = TRUE)

love.plot(weight_ps,
          abs = TRUE,
          binary = "std",
          thresholds = .1)

#### compute weighted difference (ATT)
matchdiff_ps <- lm(health ~ Apps,
                 data = app_health,
                 weights = weight_ps$weights)

tidy(matchdiff_ps, conf.int = TRUE)
```

**Using Steve's propensity matching process, having a health app is associated with a 0.066 increase in self-rated health that is significant at the 95% level.** 


```{r Common Support Graph}

ggplot(app_health,aes(x=propensity, color = factor(Apps),weight = ipw)) + 
  geom_density() +
  labs(xlab = "Propensity Score", ylab = "Density",title = "Common Support Graph")
```


### Treatment Effect

```{r}
library(causalweight)
```
    
    
```{r}
#outcome
Y <- app_health |> 
  pull(health)

#treatment
D <- app_health |> 
  pull(Apps)

#matching variables
X <- app_health |> 
  select(IncomeRanges, Age, HealthInsurance, Education, white, black, hisp, asian, other_race, female) |> 
  as.matrix()

#get the average treatment effect
IPW <- treatweight(Y,D,X,trim = 0,logit=TRUE)

IPW$effect
```

ATE of 0.05 -- similar to the earlier estimation. The ATE asks - what would the effect be if someone who doesn't have the app were to get an app? 


# Research Question 2:  Does making decisions based  on health apps correlate with improve self-rated health?

```{r}
dec_health <- dec_health |> relocate(Decision) |> select(-Tablet_MakeDecision)
glimpse(dec_health)
```


```{r data set up - weights}
# add weights

dec_health <- dec_health |> 
  mutate(weight = 1)

# estimate treatment effects

dec_est_1 <- lm(health ~ Decision,
           data = dec_health,
           weights = weight)

tidy(dec_est_1, conf.int = TRUE)
```

    This gives a coefficient of 0.02 on the "treatment," that is _not_ staitistically significant at the 95% level. This means that decisions based on the app makes you a bit more likely to have good health  (5 = excellent and 1 = poor)
    

```{r balance table}
dec_health |> 
  group_by(Decision) |> 
  summarize(across(IncomeRanges:female,~mean(.x)))
```

The balance here is also pretty good! **check why that is**

## Matching 

*come back to see if we want the ATT or the ATE*

Use all the variables except for the treatment (Apps) and the GeneralHealth variables. 

```{r}
dec_match_1 <- matchit(Decision ~ IncomeRanges + Age + HealthInsurance + Education + white + black + hisp + asian + other_race + female,
                  data = dec_health,
                  method = "nearest",
                  distance = "mahalanobis",
                  estimand = "ATT",
                  ratio = 3, #to make it a 3-nearest-matching
                  replace = TRUE)

summary(dec_match_1,
        un = FALSE,
        improvement = FALSE)
```


```{r Post-Matching average treatment on the treated effect of Apps on GeneralHealth}

#### get matched data for calculating weighted difference
dec_md1 <- match.data(dec_match_1)

#### compute weighted difference (ATT)
dec_matchdiff1 <- lm(health ~ Decision,
                 data = dec_md1,
                 weights = weights)
tidy(dec_matchdiff1, conf.int = TRUE)

```

This gives a -0.034 effect that is not statistically significant at the 95% level


```{r post matching balance}
dec_md1 |> 
  group_by(Decision) |> 
  summarize(across(IncomeRanges:female,~weighted.mean(.x,weights)))
```

Better matching - though it was pretty close. 

### Propensity Matching

```{r Estimate propensity score}
#estimate the propensity score
dec_p <- glm(Decision ~ IncomeRanges + Age + HealthInsurance + Education + white + black + hisp + asian + other_race + female,
         data = dec_health, family = binomial(link = 'logit'))

#get predicted values
dec_health <- dec_health |> 
  mutate(propensity = predict(dec_p,type = 'response'))

glimpse(dec_health)
```

Check if propensity is between 0 and 1

```{r}
range(dec_health$propensity)
```

Yes, all good. 


```{r create ipw and estimate the ATT}
#create IPW weights
dec_health <- dec_health |> 
  mutate(ipw = case_when(
    Decision == 1 ~ 1/propensity,
    Decision == 0 ~ 1/(1-propensity)
  ))

#and use to weight regressions

lm(health ~ Decision,
   data = dec_health,
   weights = ipw)
```

Treatment effect of -0.031 points (on a 5 points scale of health).

```{r steve weighting methods}
#### do the weighting
dec_weight_ps <- weightit(Decision ~ IncomeRanges + Age + HealthInsurance + Education + white + black + hisp + asian + other_race + female,
                  data = dec_health,
                  method = "ps",
                  estimand = "ATT")

#### summary
summary(dec_weight_ps)

#### cobalt balance checks
bal.plot(dec_weight_ps,
         which = "both",
         mirror = TRUE)

love.plot(dec_weight_ps,
          abs = TRUE,
          binary = "std",
          thresholds = .1)

#### compute weighted difference (ATT)
dec_matchdiff_ps <- lm(health ~ Decision,
                 data = dec_health,
                 weights = dec_weight_ps$weights)

tidy(dec_matchdiff_ps, conf.int = TRUE)
```

Gives an estimate on -0.04 for treatment, but still not staistically significant.


```{r Common Support Graph}

ggplot(dec_health,aes(x=propensity, color = factor(Decision),weight = ipw)) + 
  geom_density() +
  labs(xlab = "Propensity Score", ylab = "Density",title = "Common Support Graph")
```


### Treatment Effect

```{r}
library(causalweight)
```
    
    
```{r}
#outcome
dec_Y <- dec_health |> 
  pull(health)

#treatment
dec_D <- dec_health |> 
  pull(Decision)

#matching variables
dec_X <- dec_health |> 
  select(IncomeRanges, Age, HealthInsurance, Education, white, black, hisp, asian, other_race, female) |> 
  as.matrix()

#get the average treatment effect
dec_IPW <- treatweight(dec_Y,dec_D,dec_X,trim = 0,logit=TRUE)

dec_IPW$effect
```

ATE is -0.031, which again is very similar. 